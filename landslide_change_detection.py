# -*- coding: utf-8 -*-
"""Landslide_Change_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F9ET5P4Sa_yMystq2euRTkPjT6SngZc5
"""

import tensorflow as tf
from tensorflow.keras import layers, models
import tensorflow.keras.backend as K

class ConvEncoderBlock(layers.Layer):
    def __init__(self, filters):
        super(ConvEncoderBlock, self).__init__()
        self.conv = layers.Conv2D(filters, 3, padding='same')
        self.bn = layers.BatchNormalization()
        self.relu = layers.ReLU()

    def call(self, x, training=False):
        x = self.conv(x)
        x = self.bn(x, training=training)
        x = self.relu(x)
        return x

class ConditionalPositionEmbedding(layers.Layer):
    def __init__(self, channels, kernel_size=3):
        super(ConditionalPositionEmbedding, self).__init__()
        self.dwconv = layers.DepthwiseConv2D(kernel_size, padding='same')

    def call(self, x):
        return x + self.dwconv(x)

class LocallyGroupedSelfAttention(layers.Layer):
    def __init__(self, dim, num_heads, window_size=7):
        super(LocallyGroupedSelfAttention, self).__init__()
        self.dim = dim
        self.num_heads = num_heads
        self.window_size = window_size
        self.scale = (dim // num_heads) ** -0.5
        self.qkv = layers.Dense(dim * 3)
        self.proj = layers.Dense(dim)

    def call(self, x, H, W):
        B = tf.shape(x)[0]
        # Reshape from [B, H*W, dim] to [B, H, W, dim]
        x = tf.reshape(x, [B, H, W, self.dim])

        # Partition into windows
        # The original code caused the error here if H or W was not divisible by window_size
        # Ensure H and W are divisible by self.window_size before this step
        x = tf.reshape(x, [B, H // self.window_size, self.window_size, W // self.window_size, self.window_size, self.dim])
        x = tf.transpose(x, [0, 1, 3, 2, 4, 5])
        x = tf.reshape(x, [-1, self.window_size * self.window_size, self.dim])

        # QKV projection
        qkv = self.qkv(x)
        qkv = tf.reshape(qkv, [-1, self.window_size * self.window_size, 3, self.num_heads, self.dim // self.num_heads])
        qkv = tf.transpose(qkv, [2, 0, 3, 1, 4])
        q, k, v = qkv[0], qkv[1], qkv[2]

        # Attention
        attn = tf.matmul(q, k, transpose_b=True) * self.scale
        attn = tf.nn.softmax(attn, axis=-1)
        x = tf.matmul(attn, v)
        x = tf.transpose(x, [0, 2, 1, 3])
        x = tf.reshape(x, [-1, self.window_size * self.window_size, self.dim])

        # Projection
        x = self.proj(x)

        # Reshape back
        x = tf.reshape(x, [B, H // self.window_size, W // self.window_size, self.window_size, self.window_size, self.dim])
        x = tf.transpose(x, [0, 1, 3, 2, 4, 5])
        x = tf.reshape(x, [B, H, W, self.dim])
        x = tf.reshape(x, [B, H * W, self.dim])

        return x

class GlobalSubsampledAttention(layers.Layer):
    def __init__(self, dim, num_heads, window_size=7):
        super(GlobalSubsampledAttention, self).__init__()
        self.dim = dim
        self.num_heads = num_heads
        self.window_size = window_size
        self.scale = (dim // num_heads) ** -0.5
        self.qkv = layers.Dense(dim * 3)
        self.proj = layers.Dense(dim)
        self.subsample = layers.DepthwiseConv2D(window_size, strides=window_size, padding='valid')

    def call(self, x, H, W):
        B = tf.shape(x)[0]
        # Reshape from [B, H*W, dim] to [B, H, W, dim]
        x = tf.reshape(x, [B, H, W, self.dim])

        # Subsample for global keys
        # Ensure H and W are divisible by self.window_size for valid padding
        keys = tf.transpose(x, [0, 3, 1, 2])
        keys = self.subsample(keys)
        keys = tf.reshape(keys, [B, self.dim, -1])
        keys = tf.transpose(keys, [0, 2, 1])

        # QKV projection
        x = tf.reshape(x, [B, H * W, self.dim]) # Reshape back to [B, H*W, dim] for QKV projection
        qkv = self.qkv(x)
        qkv = tf.reshape(qkv, [B, H * W, 3, self.num_heads, self.dim // self.num_heads])
        qkv = tf.transpose(qkv, [2, 0, 3, 1, 4])
        q, k, v = qkv[0], qkv[1], qkv[2]

        # Attention with subsampled keys
        attn = tf.matmul(q, keys, transpose_b=True) * self.scale
        attn = tf.nn.softmax(attn, axis=-1)
        x = tf.matmul(attn, v)
        x = tf.transpose(x, [0, 2, 1, 3])
        x = tf.reshape(x, [B, H * W, self.dim])

        # Projection
        x = self.proj(x)
        return x

class TransformerBlock(layers.Layer):
    def __init__(self, dim, num_heads, window_size=8): # Changed window_size to 8
        super(TransformerBlock, self).__init__()
        self.cpe = ConditionalPositionEmbedding(dim)
        self.lsa = LocallyGroupedSelfAttention(dim, num_heads, window_size)
        self.gsa = GlobalSubsampledAttention(dim, num_heads, window_size)
        self.norm1 = layers.LayerNormalization(epsilon=1e-6)
        self.norm2 = layers.LayerNormalization(epsilon=1e-6)
        self.ffn = tf.keras.Sequential([
            layers.Dense(dim * 4),
            layers.ReLU(),
            layers.Dense(dim)
        ])
        self.window_size = window_size # Store window_size to check divisibility

    def call(self, x, training=False):
        B, H, W, C = tf.shape(x)

        # Add assertion to check if H and W are divisible by window_size
        tf.debugging.assert_equal(H % self.window_size, 0, message=f"Input height {H} must be divisible by window size {self.window_size}")
        tf.debugging.assert_equal(W % self.window_size, 0, message=f"Input width {W} must be divisible by window size {self.window_size}")


        x = tf.transpose(x, [0, 3, 1, 2])
        x = self.cpe(x)
        x = tf.transpose(x, [0, 2, 3, 1])
        # Reshape to [B, H*W, C] for attention layers
        x = tf.reshape(x, [B, H * W, C])

        # LSA expects input shape [B, H*W, dim] and H, W
        x = x + self.lsa(self.norm1(x), H, W)

        # GSA expects input shape [B, H*W, dim] and H, W
        x = x + self.gsa(self.norm2(x), H, W)

        # FFN
        x = x + self.ffn(self.norm2(x))

        # Reshape back to [B, H, W, C]
        x = tf.reshape(x, [B, H, W, C])
        return x

class AttentionGate(layers.Layer):
    def __init__(self, channels):
        super(AttentionGate, self).__init__()
        self.conv_g = layers.Conv2D(channels // 2, 1, padding='same')
        self.conv_x = layers.Conv2D(channels // 2, 1, padding='same')
        self.conv_psi = layers.Conv2D(1, 1, padding='same')
        self.global_avg_pool = layers.GlobalAveragePooling2D()
        self.fc1 = layers.Dense(channels // 2, activation='relu')
        self.fc2 = layers.Dense(channels, activation='sigmoid')

    def call(self, g, x):
        # Channel attention
        g_pool = self.global_avg_pool(g)
        x_pool = self.global_avg_pool(x)
        attn_channel = self.fc1(g_pool + x_pool)
        attn_channel = self.fc2(attn_channel)
        # Expand dimensions to match spatial dimensions of feature maps
        attn_channel = tf.expand_dims(tf.expand_dims(attn_channel, 1), 1)

        # Spatial attention
        g1 = self.conv_g(g)
        x1 = self.conv_x(x)
        psi = tf.nn.sigmoid(self.conv_psi(tf.nn.relu(g1 + x1)))

        # Combine
        # Apply both channel and spatial attention
        return x * psi * attn_channel

class GatedConvDecoder(layers.Layer):
    def __init__(self, in_channels, out_channels):
        super(GatedConvDecoder, self).__init__()
        self.transconv = layers.Conv2DTranspose(out_channels, 2, strides=2, padding='same') # Changed kernel_size to 2
        self.conv = layers.Conv2D(out_channels, 3, padding='same')
        self.bn = layers.BatchNormalization()
        self.relu = layers.ReLU()
        self.attention_gate = AttentionGate(out_channels)

    def call(self, x, skip, training=False):
        x = self.transconv(x)
        skip = self.attention_gate(x, skip) # Apply attention gate to the skip connection
        x = self.conv(x + skip)
        x = self.bn(x, training=training)
        x = self.relu(x)
        return x

class CDCTNet(models.Model):
    def __init__(self, in_channels=3, num_classes=2):
        super(CDCTNet, self).__init__()
        # Encoder
        self.conv1 = ConvEncoderBlock(32) # Output size: H/1, W/1
        self.pool1 = layers.MaxPooling2D(2) # Output size: H/2, W/2
        self.conv2 = ConvEncoderBlock(64) # Output size: H/2, W/2
        self.pool2 = layers.MaxPooling2D(2) # Output size: H/4, W/4
        self.conv3 = ConvEncoderBlock(128) # Output size: H/4, W/4
        self.pool3 = layers.MaxPooling2D(2) # Output size: H/8, W/8
        self.conv4 = ConvEncoderBlock(256) # Output size: H/8, W/8
        self.pool4 = layers.MaxPooling2D(2) # Output size: H/16, W/16

        # Transformer
        # Input to transformer should have dimensions divisible by window_size
        # With a 256x256 input, pool4 results in 16x16. With window_size=8, this is divisible.
        self.transformer = TransformerBlock(256, num_heads=8, window_size=8) # Changed window_size


        self.dec1 = GatedConvDecoder(256, 128) # Takes 256 channels, outputs 128 channels


        self.dec2 = GatedConvDecoder(128, 64) # Takes 128 channels, outputs 64 channels


        self.dec3 = GatedConvDecoder(64, 32) # Takes 64 channels, outputs 32 channels


        self.dec1 = GatedConvDecoder(256, 128)


        self.dec2 = GatedConvDecoder(128, 64)


        self.dec3 = GatedConvDecoder(64, 32)


        self.dec4 = GatedConvDecoder(32, 16) # Added one more decoder layer

        # Final Convolution: Input dec4 output (256x256, 16), Output (256x256, num_classes)
        self.final_conv = layers.Conv2D(num_classes, 1, padding='same')

    def call(self, x, training=False):
        # Input size: [B, 256, 256, 3]
        # Encoder
        e1 = self.conv1(x, training=training) # e1: [B, 256, 256, 32]
        p1 = self.pool1(e1) # p1: [B, 128, 128, 32]

        e2 = self.conv2(p1, training=training) # e2: [B, 128, 128, 64]
        p2 = self.pool2(e2) # p2: [B, 64, 64, 64]

        e3 = self.conv3(p2, training=training) # e3: [B, 64, 64, 128]
        p3 = self.pool3(e3) # p3: [B, 32, 32, 128]

        e4 = self.conv4(p3, training=training) # e4: [B, 32, 32, 256]
        p4 = self.pool4(e4) # p4: [B, 16, 16, 256]

        # Transformer
        # Input p4 is 16x16. With window_size=8, 16 is divisible by 8.
        t = self.transformer(p4, training=training) # t: [B, 16, 16, 256]


        d1 = self.dec1(t, e4, training=training) # d1: [B, 32, 32, 128]


        d2 = self.dec2(d1, e3, training=training) # d2: [B, 64, 64, 64]


        d3 = self.dec3(d2, e2, training=training) # d3: [B, 128, 128, 32]


        d4 = self.dec4(d3, e1, training=training) # d4: [B, 256, 256, 16]

        # Final Convolution
        out = self.final_conv(d4) # out: [B, 256, 256, num_classes]

        return out

class HybridLoss:
    def __init__(self, alpha=0.25, gamma=2.0):
        self.alpha = alpha
        self.gamma = gamma

    def dice_loss(self, y_true, y_pred):
        # Apply sigmoid to logits to get probabilities
        y_pred = tf.nn.sigmoid(y_pred)
        # Flatten spatial dimensions for calculation
        y_true_flat = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])
        y_pred_flat = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])

        # Calculate intersection and union per class
        intersection = tf.reduce_sum(y_pred_flat * y_true_flat, axis=0)
        union = tf.reduce_sum(y_pred_flat, axis=0) + tf.reduce_sum(y_true_flat, axis=0)

        # Calculate Dice coefficient per class
        dice = (2. * intersection + 1e-6) / (union + 1e-6)

        # Return mean Dice loss across classes
        return 1 - tf.reduce_mean(dice)

    def focal_loss(self, y_true, y_pred):
        # Ensure y_true and y_pred have the same shape
        tf.debugging.assert_equal(tf.shape(y_true), tf.shape(y_pred), message="y_true and y_pred must have the same shape for focal loss.")

        # Calculate Binary Cross-Entropy with logits
        bce = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)

        # Calculate probability of the predicted class
        y_pred_prob = tf.nn.sigmoid(y_pred)
        # pt = p if y_true == 1 else 1 - p
        pt = y_true * y_pred_prob + (1 - y_true) * (1 - y_pred_prob)

        # Calculate focal loss
        focal = self.alpha * (1 - pt) ** self.gamma * bce

        # Return mean focal loss
        return tf.reduce_mean(focal)

    def __call__(self, y_true, y_pred):
        # Ensure y_true and y_pred have the same shape before calculating losses
        tf.debugging.assert_equal(tf.shape(y_true), tf.shape(y_pred), message="y_true and y_pred must have the same shape for HybridLoss.")

        # Binary Cross-Entropy loss with logits
        bce_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))

        # Dice loss
        dice_loss = self.dice_loss(y_true, y_pred)

        # Focal loss
        focal_loss = self.focal_loss(y_true, y_pred)

        # Combine losses
        return bce_loss + dice_loss + focal_loss

# Example usage
if __name__ == "__main__":
    # Define input shape (batch size, height, width, channels)
    input_shape = [1, 224, 22, 3]
    num_classes = 2 # Assuming 2 classes for segmentation

    # Create the model
    model = CDCTNet(in_channels=input_shape[-1], num_classes=num_classes)